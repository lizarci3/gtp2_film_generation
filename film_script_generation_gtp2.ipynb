{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "film_script_generation_gtp2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1EYnGMObGkAEitlKNQrf2Zp07Axl7nPXX",
      "authorship_tag": "ABX9TyPRhvId+aDGHdD8SnkxCZ4N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "aa5c8fc8a26540548c3bcffe8fafdb23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3ee2d68ca90942c5a9dcf9ab5bca86c5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0c19d55fb9034a5083ef73157db5ca59",
              "IPY_MODEL_81784ab0837b4e26a9ac1cf337c1c040"
            ]
          }
        },
        "3ee2d68ca90942c5a9dcf9ab5bca86c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c19d55fb9034a5083ef73157db5ca59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b344387a5c364bb58ed453d65d6de52f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2ec8f040e591479f89217ea1ae2da181"
          }
        },
        "81784ab0837b4e26a9ac1cf337c1c040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e978aeffd500426bbeda909081b8af2c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04M/1.04M [00:01&lt;00:00, 800kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08eac4696d90492685aef616c1703cbd"
          }
        },
        "b344387a5c364bb58ed453d65d6de52f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2ec8f040e591479f89217ea1ae2da181": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e978aeffd500426bbeda909081b8af2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08eac4696d90492685aef616c1703cbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51480b46e106480fbb5d1ec7272144fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4d6904455f984331ba5f40c804578fb0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cb30184998f14bba9e188ef61fef2957",
              "IPY_MODEL_fae2ee93169b4a1696d80e992aa58c75"
            ]
          }
        },
        "4d6904455f984331ba5f40c804578fb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb30184998f14bba9e188ef61fef2957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9cee8b887b63470c9970501a01f13ea1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_11c52e7dd7d84db2b673cbf18572c167"
          }
        },
        "fae2ee93169b4a1696d80e992aa58c75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9e668e2344154db292b8012bc9163434",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 1.39MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd419b48563a42d7bc01ff05a9b35c83"
          }
        },
        "9cee8b887b63470c9970501a01f13ea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "11c52e7dd7d84db2b673cbf18572c167": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e668e2344154db292b8012bc9163434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd419b48563a42d7bc01ff05a9b35c83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "929ba0eb1a7f40ed83f20abc83c65123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2574ee0e0ebf49dc98641d9aaa0d1503",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ec9e89473325490fbd4d87082a26deaa",
              "IPY_MODEL_dd1a1d8c83f8487388083e9cddf9bb81"
            ]
          }
        },
        "2574ee0e0ebf49dc98641d9aaa0d1503": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec9e89473325490fbd4d87082a26deaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7a549dfcb0c74cd795e6259da78b30b2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 665,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 665,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df351c3787924421bd4f6605f6efddcc"
          }
        },
        "dd1a1d8c83f8487388083e9cddf9bb81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5f17b761336b4ea9ad022fc1ddd56b25",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 665/665 [00:00&lt;00:00, 938B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ee44ccbc6c2249a29148d112362b4a0a"
          }
        },
        "7a549dfcb0c74cd795e6259da78b30b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df351c3787924421bd4f6605f6efddcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f17b761336b4ea9ad022fc1ddd56b25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ee44ccbc6c2249a29148d112362b4a0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "34e87cdf405f4439a2afab55932bfefb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_66358a9a54bf42a187ad352bf2fcf33d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4dc59c09ebd24d37bc1e7302df519d76",
              "IPY_MODEL_760133f2cc4641fc90f210ad1b555fd4"
            ]
          }
        },
        "66358a9a54bf42a187ad352bf2fcf33d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4dc59c09ebd24d37bc1e7302df519d76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6e43df86f97e431e85152a7d87c45b13",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 548118077,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 548118077,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f8cbdca175ca45ab9a2a7363af00885f"
          }
        },
        "760133f2cc4641fc90f210ad1b555fd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5b24986ce36541c383c328f2561a06d0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [00:12&lt;00:00, 43.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9d9b26b5ec2e4225b071d82016386083"
          }
        },
        "6e43df86f97e431e85152a7d87c45b13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f8cbdca175ca45ab9a2a7363af00885f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5b24986ce36541c383c328f2561a06d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9d9b26b5ec2e4225b071d82016386083": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lizarci3/gtp2_film_generation/blob/master/film_script_generation_gtp2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zngvnu2UwJbf",
        "colab_type": "text"
      },
      "source": [
        "# Background\n",
        "\n",
        "Original article can be found [here](https://towardsdatascience.com/film-script-generation-with-gpt-2-58601b00d371)\n",
        "\n",
        "Repo [here](https://github.com/cdpierse/script_buddy_v2)\n",
        "\n",
        "The author used film scripts (~60 MB) of data scraped from the Internet Movie Script Database (IMSDB) in order to fine-tune a GTP2 to write a film script.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_StsRw6xxYJ2",
        "colab_type": "text"
      },
      "source": [
        "The author of this script only had ~1300 scripts to use, however, on averagea screenplay has 30,000 words. So the dataset has close to 40 million sequences of words.\n",
        "\n",
        "The author wanted the model to be able to generate entire sequences of scripts with mixed scripted elements in each sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_x3MxXos4Z6c",
        "colab_type": "text"
      },
      "source": [
        "This fine-tuning is developed based on hugginface's example on fine-tuning dataset found in run_language_modeling.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Oj1u6_enWP1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "bd913a38-c0d7-4a25-8bcd-10b1f8d59f60"
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=7ca647262279ee7387b78f6a2680e902577af13fd5d4faf20cfbc545260930eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.8 GB  |     Proc size: 111.2 MB\n",
            "GPU RAM Free: 15079MB | Used: 0MB | Util   0% | Total     15079MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkEM-rEJ-xrA",
        "colab_type": "text"
      },
      "source": [
        "# Preparing the data\n",
        "\n",
        "The script data is loaded into the model in batches were the data has already been tokenized for GPT-2. In the repo, the ScriptData class splits the entire dataset into tokenized blocks of tensors.\n",
        "\n",
        "Once the data has been properly prepared, these blocks are loaded in batches into a GPT-2 in a training loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r-ZwZkNMMPf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "17d801bd-9291-4019-cf9e-403284b7eeb9"
      },
      "source": [
        "!pip install git+https://github.com/huggingface/transformers #just doing a pip install transformers creates some sync problems"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-kdinxqjq\n",
            "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-kdinxqjq\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (1.18.5)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 40.7MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 56.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (0.7)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.0.2) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.0.2) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (2020.6.20)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.2) (0.16.0)\n",
            "Building wheels for collected packages: transformers, sacremoses\n",
            "  Building wheel for transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-3.0.2-cp36-none-any.whl size=824179 sha256=86a7ebc31e9d7ecedab959aa6bf391beb0791922552583d5b6aa0b66a14cf356\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7lt6fekb/wheels/70/d3/52/b3fa4f8b8ef04167ac62e5bb2accb62ae764db2a378247490e\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=b0593864f597789038eaa5fc899fa3378652c914ec676d2e9015c6b4c137814f\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built transformers sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFh74RApLrem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
        "import numpy as np\n",
        "import os\n",
        "import logging \n",
        "import pickle\n",
        "import logging\n",
        "import random"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBQQEEeTFt7v",
        "colab_type": "text"
      },
      "source": [
        "The gpt2-medium model used in this work has 12 layers ~345 million parameters and took ~6h to train (with 3 epochs).\n",
        "\n",
        "The first thing that needs to be done is to upload the model and tokenizer from the pre-trained transformers package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VxKJlVLf5zs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b9305ac1-9b84-4bf1-ccd4-7471a57290e6"
      },
      "source": [
        "device = 'cpu'\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'\n",
        "\n",
        "device"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R2k5VtgFa-m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "aa5c8fc8a26540548c3bcffe8fafdb23",
            "3ee2d68ca90942c5a9dcf9ab5bca86c5",
            "0c19d55fb9034a5083ef73157db5ca59",
            "81784ab0837b4e26a9ac1cf337c1c040",
            "b344387a5c364bb58ed453d65d6de52f",
            "2ec8f040e591479f89217ea1ae2da181",
            "e978aeffd500426bbeda909081b8af2c",
            "08eac4696d90492685aef616c1703cbd",
            "51480b46e106480fbb5d1ec7272144fa",
            "4d6904455f984331ba5f40c804578fb0",
            "cb30184998f14bba9e188ef61fef2957",
            "fae2ee93169b4a1696d80e992aa58c75",
            "9cee8b887b63470c9970501a01f13ea1",
            "11c52e7dd7d84db2b673cbf18572c167",
            "9e668e2344154db292b8012bc9163434",
            "fd419b48563a42d7bc01ff05a9b35c83",
            "929ba0eb1a7f40ed83f20abc83c65123",
            "2574ee0e0ebf49dc98641d9aaa0d1503",
            "ec9e89473325490fbd4d87082a26deaa",
            "dd1a1d8c83f8487388083e9cddf9bb81",
            "7a549dfcb0c74cd795e6259da78b30b2",
            "df351c3787924421bd4f6605f6efddcc",
            "5f17b761336b4ea9ad022fc1ddd56b25",
            "ee44ccbc6c2249a29148d112362b4a0a",
            "34e87cdf405f4439a2afab55932bfefb",
            "66358a9a54bf42a187ad352bf2fcf33d",
            "4dc59c09ebd24d37bc1e7302df519d76",
            "760133f2cc4641fc90f210ad1b555fd4",
            "6e43df86f97e431e85152a7d87c45b13",
            "f8cbdca175ca45ab9a2a7363af00885f",
            "5b24986ce36541c383c328f2561a06d0",
            "9d9b26b5ec2e4225b071d82016386083"
          ]
        },
        "outputId": "83c62f79-4c95-47cf-bfc7-d7a11bc1ba28"
      },
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "model.to(device)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa5c8fc8a26540548c3bcffe8fafdb23",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descriptâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51480b46e106480fbb5d1ec7272144fa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "929ba0eb1a7f40ed83f20abc83c65123",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=665.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34e87cdf405f4439a2afab55932bfefb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=548118077.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KINDLD6oGjr4",
        "colab_type": "text"
      },
      "source": [
        "* In order to fine tune this pre-trained model you need to create a training loop where you progressively load a batch of script sequences from the entire dataset.\n",
        "* Each batch is like a tokenized block of tensors from the data (done in ScriptData).\n",
        "* An important parameter to consider is the batch size. Large batch sizes can result in running out of GPU memory fast. To start, you can choose a batch of 1 and then test how much you can test it.\n",
        "\n",
        "* In this work his batch size was 7."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heJFj7VS_V-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
        "from transformers import (\n",
        "    GPT2Config,\n",
        "    GPT2LMHeadModel,\n",
        "    GPT2Tokenizer,\n",
        "    PreTrainedModel,\n",
        "    PreTrainedTokenizer,\n",
        ")\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7W7V0_cZciV",
        "colab_type": "text"
      },
      "source": [
        "# Preparing the Data\n",
        "\n",
        "The following ScriptData class splits the dataset into tokenized blocks of tensors. These blocks will then be loaded in batches into the training loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzBvVN9g3wgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FILE_PATH = \"/content/drive/My Drive/WJ/film_text.txt\" # ~ 60 MB\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class ScriptData(Dataset):\n",
        "\n",
        "  def __init__(\n",
        "      self, #instance of the class ScriptData\n",
        "      tokenizer: PreTrainedTokenizer,\n",
        "      file_path: str, \n",
        "      block_size = 512, # Fine-tuning item\n",
        "      overwrite_cache = False\n",
        "  ):\n",
        "\n",
        "      assert os.path.isfile(file_path) #assert raises an error if condition False\n",
        "\n",
        "      block_size = block_size - (tokenizer.max_len - tokenizer.max_len_single_sentence)\n",
        "\n",
        "      directory, filename = os.path.split(file_path)\n",
        "\n",
        "      #Create the path/filename for the cached file\n",
        "      # so that is stored in the same folder and it stores which block size we used\n",
        "    \n",
        "      cached_features_file = os.path.join(directory,\"gpt2\"+\"_\"+str(block_size)+\"_\"+filename)\n",
        "\n",
        "      #if the file already exists and if overwrite_cache is set to False don't overwrite\n",
        "      if os.path.exists(cached_features_file) and not overwrite_cache:\n",
        "        logger.info(f\"Loading features from cached file {cached_features_file}\")\n",
        "\n",
        "        with open(cached_features_file, 'rb') as cache:\n",
        "          self.examples = pickle.load(cache)\n",
        "          logger.debug(\"Loaded examples from cache\")\n",
        "\n",
        "      else:\n",
        "\n",
        "        logger.info(f\"Creating features from file {filename} at {directory}\")\n",
        "\n",
        "        self.examples = []\n",
        "\n",
        "        with open(file_path, encoding=\"utf-8\") as f:\n",
        "          text = f.read()\n",
        "          logger.debug(\"Succesfully read text from file\")\n",
        "\n",
        "        #convert_tokens_to_ids = Converts a token string (or a sequence of tokens) in a single integer id (or sequence of ids), using the vocabulary\n",
        "        tokenized_text = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))\n",
        "\n",
        "        #slice in steps of block_size the text\n",
        "        #append in examples\n",
        "\n",
        "        for i in range(0, len(tokenized_text) - block_size + 1, block_size):\n",
        "          self.examples.append(\n",
        "              tokenizer.build_inputs_with_special_tokens( #From Bert model: \n",
        "                  tokenized_text[i : i + block_size]\n",
        "              )\n",
        "          )\n",
        "\n",
        "        logger.info(f\"Saving features into cached file {cached_features_file}\")\n",
        "\n",
        "        # save it\n",
        "        with open(cached_features_file, \"wb\") as cache:\n",
        "          pickle.dump(self.examples, cache, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.examples)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    return torch.tensor(self.examples[item], dtype=torch.long)\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap9UBZprEuWu",
        "colab_type": "text"
      },
      "source": [
        "# Fine-tuning GPT-2: Training\n",
        "\n",
        "A GPU is necessary when training this model. We are using a dataset of film scripts that is about 60 MB to train. This text has been prepared by scrapping IMSDB (see in the repo the specifics of the scrapping)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAJXisafcko_",
        "colab_type": "text"
      },
      "source": [
        "We talked about how to fine tune the model (or optimize it on a custom dataset of tokenized text) you need to create a TRAINING LOOP WHERE YOU PROGRESSIVELY LOAD A BATCH OF SCRIPT SEQUENCES FROM THE DATASET.\n",
        "\n",
        "* Each batch (a batch of tokenized tensor) is run through the language model head as BOTH its intput and target labels.\n",
        "* From this step we return the loss and logits (i.e., prediction scores) to conduct the backward pass on the gradients.\n",
        "* Every X number of batches set up an evaluation step to generate a batch of text. This helps us understand how well the model is optimizing and being fine-tuned to the specific text.\n",
        "* Transformer's generate function provides a number of different decoding methods to get the best results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NCDHbQUZFnR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_dir = '/content/drive/My Drive/WJ/'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbX0rIZoeMwi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "87b7b63f-15f9-4f28-a41a-aa40649ad93c"
      },
      "source": [
        "dataset = ScriptData(tokenizer= tokenizer, file_path= FILE_PATH )\n",
        "script_loader = DataLoader(dataset,batch_size=4,shuffle=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1294: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2QWPMoibZ4y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "07a3685b-2a67-497c-da1e-5ec2a7cc03ba"
      },
      "source": [
        "type(script_loader)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataloader.DataLoader"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL3xEeRDZnz2",
        "colab_type": "text"
      },
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PufIi3UYUdb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 1 #starting point, author used in the end a batch_size of 7\n",
        "EPOCHS = 1 # the author mentions he used in total 3 full epochs lasting ~6h for training\n",
        "LEARNING_RATE = 0.00002\n",
        "WARMUP_STEPS = 10000"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTcMfEkAZ2MS",
        "colab_type": "text"
      },
      "source": [
        "Start the optimizer, scheduler and set up the loss, batch counts to start at zero"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io3W0TKaYUgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.train()\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=-1)\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjD7JoJ87jbt",
        "colab_type": "text"
      },
      "source": [
        "## Just for testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pE1xdpHCYUko",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "337e7471-6485-4ab7-94e2-c9919c70d053"
      },
      "source": [
        "script_count = 0\n",
        "sum_loss = 0.0\n",
        "batch_count = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  print(f\"EPOCH {epoch} started\"+'='*30)\n",
        "\n",
        "  j = 0\n",
        "  nsamples = 199\n",
        "\n",
        "  for idx, script in enumerate(script_loader):\n",
        "\n",
        "    if j>nsamples:\n",
        "      break\n",
        "\n",
        "    else:\n",
        "      print(idx, script, script[0].shape) #512 was what we used as block size in ScriptData\n",
        "\n",
        "      outputs = model(script.to(device), labels=script.to(device))\n",
        "\n",
        "      loss, logits = outputs[:2] # language modeling loss and prediction scores of the language modeling head \n",
        "      loss.backward()\n",
        "\n",
        "      sum_loss = sum_loss + loss.detach().data\n",
        "      script_count = script_count + 1\n",
        "      print('Sum loss', sum_loss, 'script_count', script_count)\n",
        "      \n",
        "      #once we have loaded enough scripts == batch_size\n",
        "\n",
        "      j = j + 1 \n",
        "\n",
        "      if script_count == BATCH_SIZE:\n",
        "        print('script_count equal to batch_size')\n",
        "        script_count = 0 # re-start script counter\n",
        "        batch_count = batch_count + 1 # how many full batches we have\n",
        "        print('batch_count', batch_count)\n",
        "        \n",
        "        optimizer.step() # perform an optimization step\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad() # clear the gradients from the last step, PyTorch accumulates the gradients so before starting to propagate we need to set them to zero\n",
        "        model.zero_grad()\n",
        "\n",
        "\n",
        "        ## As opposed to the jokes generation script, this script generates text\n",
        "        ## Apparently, every X number of batches to see how it is doing\n",
        "        ## here, UNDERSTAND BELOW PARAMS\n",
        "        if batch_count == 200:\n",
        "            model.eval()  \n",
        "            print(f\"sum loss {sum_loss}\")\n",
        "\n",
        "            ## see https://huggingface.co/blog/how-to-generate\n",
        "\n",
        "            sample_outputs = model.generate( #function added since version 2.4\n",
        "                                    bos_token_id=random.randint(1,30000), # I AM ASSUMIN GIS THE INPUT: The sequence used as a prompt for the generation. If `None` the method initializes  it as an empty `torch.LongTensor` of shape `(1,)`. \n",
        "                                    do_sample=True, #If set to `False` greedy decoding is used. Otherwise sampling is used. Defaults to `False` as defined in `configuration_utils.PretrainedConfig`.  \n",
        "                                    top_k=50, #The cumulative probability of parameter highest probability vocabulary tokens to keep for nucleus sampling. Must be between 0 and 1. Default to 1.  \n",
        "                                    max_length = 1000, # The max length of the sequence to be generated.  Between `min_length` and infinity. Default to 20.\n",
        "                                    top_p=0.95, #The cumulative probability of parameter highest probability vocabulary tokens to keep for nucleus sampling. Must be between 0 and 1. Default to 1.  \n",
        "                                    num_return_sequences=1 #The number of independently computed returned sequences for each element in the batch. Default to 1.\n",
        "                                )\n",
        "\n",
        "            print(\"Output:\\n\" + 100 * '-')\n",
        "            for i, sample_output in enumerate(sample_outputs):\n",
        "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
        "            \n",
        "            batch_count = 0\n",
        "            sum_loss = 0.0\n",
        "            model.train()\n",
        "        \n",
        "\n",
        "        \n",
        "\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH 0 started==============================\n",
            "0 tensor([[  607,  1735,    13,  ...,  6916,  1911,   383],\n",
            "        [  345,   588,   284,  ...,    13,   198,   220],\n",
            "        [  220,   357,  4663,  ...,   220,   220,   220],\n",
            "        [  220,   220, 26746,  ...,   262,  6546,   220]]) torch.Size([512])\n",
            "Sum loss tensor(2.0897, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 1\n",
            "1 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   344,   611,   428],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  198,   220,   220,  ...,   339, 15455,   329]]) torch.Size([512])\n",
            "Sum loss tensor(3.9353, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 2\n",
            "2 tensor([[  628,   198,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   290, 42966, 14412],\n",
            "        [   11,  6451,   379,  ...,     0,   198,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(5.9494, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 3\n",
            "3 tensor([[ 1231,   781,  8589,  ...,   319,    11,  8781],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  198,   220,   220,  ...,   220,   220,   220],\n",
            "        [  262, 12020,    13,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(7.7034, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 4\n",
            "4 tensor([[2740,   26,  198,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [  13, 1550,  257,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220]]) torch.Size([512])\n",
            "Sum loss tensor(9.7376, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 5\n",
            "5 tensor([[  220,   220,   220,  ...,   628,   198,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  318, 11123,   607,  ...,    13,   198,   198],\n",
            "        [  220,   220,   220,  ...,   284,   466,   351]]) torch.Size([512])\n",
            "Sum loss tensor(11.8831, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 6\n",
            "6 tensor([[220, 220, 220,  ..., 220, 220, 220],\n",
            "        [220, 220, 220,  ..., 383, 691, 198],\n",
            "        [220, 220, 220,  ..., 220, 220, 220],\n",
            "        [220, 220, 220,  ..., 220, 220, 220]]) torch.Size([512])\n",
            "Sum loss tensor(13.6636, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 7\n",
            "7 tensor([[  220,   220,   220,  ...,   220,   220, 29377],\n",
            "        [ 2536,   312, 29097,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,    35,     8,   198],\n",
            "        [11860,   628,   198,  ...,   262,   474,  4649]]) torch.Size([512])\n",
            "Sum loss tensor(15.6604, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 8\n",
            "8 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [   13,   220,  1439,  ...,   220,   220,   220],\n",
            "        [  220,   220, 13656,  ...,   412,  3069,  1797]]) torch.Size([512])\n",
            "Sum loss tensor(17.5943, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 9\n",
            "9 tensor([[ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  413, 3228, 9425],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ..., 3708,   11,  810]]) torch.Size([512])\n",
            "Sum loss tensor(19.6810, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 10\n",
            "10 tensor([[29089,   198,   220,  ...,   220,   220,   220],\n",
            "        [  197,   197,   197,  ...,   197,   197,   197],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ..., 50104, 28034,   734]]) torch.Size([512])\n",
            "Sum loss tensor(23.5043, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 11\n",
            "11 tensor([[  628,   198,   220,  ...,   314,   764,  7688],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [ 2751,  3336, 35106,  ...,    12,   198,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(25.8703, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 12\n",
            "12 tensor([[39677,   468,  5445,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [26246,   345,   287,  ...,   220,   220,   220],\n",
            "        [   11,   766,   644,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(27.9917, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 13\n",
            "13 tensor([[ 531,  326,   13,  ...,  220,  220,  220],\n",
            "        [ 198,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  406, 9226, 2342],\n",
            "        [ 262, 2128,  286,  ...,  220,  220,  220]]) torch.Size([512])\n",
            "Sum loss tensor(29.9737, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 14\n",
            "14 tensor([[ 1700,    30,   921,  ...,    13, 14594,   329],\n",
            "        [  220,   220,   220,  ...,   314,  1101, 11263],\n",
            "        [  220,   220,   220,  ...,   220,   220,   340],\n",
            "        [  220,  7375,  3069,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(31.8854, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 15\n",
            "15 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,  1306, 28960,  6622]]) torch.Size([512])\n",
            "Sum loss tensor(33.6654, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 16\n",
            "16 tensor([[  220,   220,   357,  ...,   220,   628,   220],\n",
            "        [  339,   338,   706,  ...,   262, 17548,    30],\n",
            "        [  314,  8072,   616,  ..., 10347,   484,   651],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(35.8763, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 17\n",
            "17 tensor([[  220,   220,   220,  ...,   517, 19647,  1143],\n",
            "        [  220,   220,   220,  ...,  3268,   319,   198],\n",
            "        [ 3111,   329,   262,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(38.1899, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 18\n",
            "18 tensor([[  220,   220,   475,  ...,   220,   220,   220],\n",
            "        [   11,   314,   760,  ...,   220,   220,   220],\n",
            "        [  683,    13, 45187,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(40.0588, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 19\n",
            "19 tensor([[ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  198,  220,  220],\n",
            "        [  13, 1114,  262,  ...,  198,  220,  220]]) torch.Size([512])\n",
            "Sum loss tensor(42.2024, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 20\n",
            "20 tensor([[ 1565,   357, 37815,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   198,   220,   220],\n",
            "        [  198,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(44.0036, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 21\n",
            "21 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [19984,  3240,    11,  ...,  1867,   262,  5089],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(45.7704, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 22\n",
            "22 tensor([[  628,   198,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  198,   220,   220,  ...,   220,   220,   220],\n",
            "        [  407,   772, 18409,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(47.4782, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 23\n",
            "23 tensor([[  628,   198,   197,  ..., 38139,    13,   220],\n",
            "        [  220,   220,   220,  ...,   198,   220,   220],\n",
            "        [  220,   220,   220,  ...,   628,   198,   220],\n",
            "        [  915,  3019,   829,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(51.0038, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 24\n",
            "24 tensor([[  220,   220,   220,  ...,    42,   309, 14165],\n",
            "        [17364,   379,   281,  ...,   220,   220,   220],\n",
            "        [ 6369, 22707, 27993,  ...,   220,   220,   220],\n",
            "        [  198,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(53.3003, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 25\n",
            "25 tensor([[  262,  5349,    30,  ..., 27285,   532, 24644],\n",
            "        [36906,  1497, 10953,  ...,   220,   220,   337],\n",
            "        [ 6423,  1309,   338,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,  5465,  4756, 16441]]) torch.Size([512])\n",
            "Sum loss tensor(55.5591, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 26\n",
            "26 tensor([[  370, 12115,  2257,  ...,   220,   220,   220],\n",
            "        [  220,   220,   632,  ...,   220,   220,   220],\n",
            "        [20373,   198,   220,  ...,   881,  1637, 23107],\n",
            "        [  220,   220,   220,  ...,  2270,   198,   220]]) torch.Size([512])\n",
            "Sum loss tensor(57.7942, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 27\n",
            "27 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [10705,  2885,    56,  ...,   220,   220,   220],\n",
            "        [  314,   892,   339,  ...,   220,   220,   220],\n",
            "        [26044,   616,   835,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(59.6279, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 28\n",
            "28 tensor([[  220,   220,   220,  ...,    11,  9245,   465],\n",
            "        [  220,   220,   220,  ..., 46159,    11, 15967],\n",
            "        [  220,   220,  2239,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(61.7324, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 29\n",
            "29 tensor([[ 220,  220,  220,  ...,  198,  220,  220],\n",
            "        [ 628,  198,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ..., 9216,  465, 6466],\n",
            "        [8147, 6239,   11,  ...,  220,  220,  220]]) torch.Size([512])\n",
            "Sum loss tensor(63.3207, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 30\n",
            "30 tensor([[ 220,  220,  337,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [1280,   13,  628,  ..., 3588,  470,  314],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220]]) torch.Size([512])\n",
            "Sum loss tensor(65.3568, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 31\n",
            "31 tensor([[ 220,  198,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220, 2492,  470],\n",
            "        [3812,  465, 2119,  ...,  220,  220,  220],\n",
            "        [ 198, 1273, 1590,  ...,   11,  198, 4360]]) torch.Size([512])\n",
            "Sum loss tensor(68.3293, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 32\n",
            "32 tensor([[  257,  1336,    12,  ..., 16034,   198,   220],\n",
            "        [  220,   220,   220,  ...,   257,   923,    13],\n",
            "        [ 8905,  9795,   198,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(70.3720, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 33\n",
            "33 tensor([[18653, 11103,   510,  ...,  2834,   340,   503],\n",
            "        [  532, 37707,   628,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(72.2077, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 34\n",
            "34 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [   11,   262,  2119,  ..., 12049,   329,   257],\n",
            "        [  220,   220,   220,  ..., 28052,    13,   220]]) torch.Size([512])\n",
            "Sum loss tensor(74.0539, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 35\n",
            "35 tensor([[  220,   220,   220,  ...,   220,   220, 44849],\n",
            "        [  197,   197,   197,  ...,  5689,    13,   220],\n",
            "        [  220,   220,   220,  ...,   198,   220,   220],\n",
            "        [ 4526, 11190, 10008,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(77.5991, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 36\n",
            "36 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220, 27489,    13],\n",
            "        [ 6099,    13,   314,  ...,   257,  3197,    13],\n",
            "        [  220,   220,   220,  ...,   220, 17051,  6089]]) torch.Size([512])\n",
            "Sum loss tensor(79.8666, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 37\n",
            "37 tensor([[ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  416,  ...,  220,  220,  220],\n",
            "        [ 220, 1168, 9900,  ...,  220,  220,  220]]) torch.Size([512])\n",
            "Sum loss tensor(81.7950, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 38\n",
            "38 tensor([[19313, 11587,   198,  ...,   197,   197,   197],\n",
            "        [  314,  1239,   481,  ...,  4329, 34644,    11],\n",
            "        [   11,   326,   338,  ...,   220,   220,   991],\n",
            "        [ 2951,   389,  4692,  ...,   632,   923,   829]]) torch.Size([512])\n",
            "Sum loss tensor(85.6587, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 39\n",
            "39 tensor([[  220,   220,   220,  ..., 25620, 39941,   198],\n",
            "        [  502,    11,  3387,  ..., 39743,     6,    50],\n",
            "        [  220,   220,   220,  ...,   628,   198,   220],\n",
            "        [  367, 12298,    42,  ...,   198,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(87.6108, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 40\n",
            "40 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,  3285,  7650,  ...,  1838,   607,   835],\n",
            "        [30459,   258,  1150,  ..., 25023,  1377, 17144]]) torch.Size([512])\n",
            "Sum loss tensor(89.9603, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 41\n",
            "41 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  197,    76, 20526,  ...,   651,   503,    13]]) torch.Size([512])\n",
            "Sum loss tensor(93.5789, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 42\n",
            "42 tensor([[6294,   13, 3334,  ...,  198,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [  13, 1867,  460,  ...,  628,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  734,  220,  198]]) torch.Size([512])\n",
            "Sum loss tensor(95.4372, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 43\n",
            "43 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  198,   220,   220,  ...,  7837, 37995,   287],\n",
            "        [ 5909,  1108,    13,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(97.3429, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 44\n",
            "44 tensor([[ 1867,  3022,    30,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   314,  1975,    13],\n",
            "        [10408,    13,   628,  ...,   220,   764,  8727],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(99.4344, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 45\n",
            "45 tensor([[31827,   198,   220,  ...,   220,   220,   220],\n",
            "        [ 1565,   198,   220,  ...,   220,   220,   220],\n",
            "        [  197,    43, 11404,  ...,   220, 37401,   290],\n",
            "        [  220,   220,   220,  ...,    13,    50,  2014]]) torch.Size([512])\n",
            "Sum loss tensor(102.9716, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 46\n",
            "46 tensor([[  220,   220,   887,  ...,   220,   220,   220],\n",
            "        [  220,   220,  5364,  ...,  6296,   510,    11],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [   11,   356,  4268,  ...,   262, 23292,   198]]) torch.Size([512])\n",
            "Sum loss tensor(105.0287, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 47\n",
            "47 tensor([[ 220,  220, 1024,  ..., 5883, 9148, 1546],\n",
            "        [ 220,  220,  220,  ..., 5118,  351,  257],\n",
            "        [ 813,   25,  628,  ...,  922, 1295,  356],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220]]) torch.Size([512])\n",
            "Sum loss tensor(106.9082, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 48\n",
            "48 tensor([[ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [8338,   13,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  198,  220,  220],\n",
            "        [6749,  338,  366,  ...,   11, 6088,  286]]) torch.Size([512])\n",
            "Sum loss tensor(109.0265, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 49\n",
            "49 tensor([[  350,  3525, 46685,  ...,   198, 30349,    82],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  262,  1994,    13,  ...,   220,   220,   220],\n",
            "        [ 1282, 14556,    13,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(111.4156, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 50\n",
            "50 tensor([[  220,   220,   220,  ...,   198,   220,   220],\n",
            "        [  220,   220,   220,  ...,   198,   220,   220],\n",
            "        [  220,   220,   220,  ...,   383,  4848,   417],\n",
            "        [  220, 36449,    56,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(113.7575, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 51\n",
            "51 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   198,   220,   220],\n",
            "        [   13,   198,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ..., 11163,   449, 27799]]) torch.Size([512])\n",
            "Sum loss tensor(115.7259, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 52\n",
            "52 tensor([[ 5883,  1503,   198,  ...,    30,  1374,   373],\n",
            "        [  220,   220,   632,  ...,   220,   220,   220],\n",
            "        [  397,   375, 19392,  ...,   220,   220,   220],\n",
            "        [  220,   399,  2518,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(117.4357, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 53\n",
            "53 tensor([[  220,   220,   220,  ..., 24356,  2706,   326],\n",
            "        [  220,   220,   220,  ...,  8643, 11319,     8],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  395,    12,   344,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(119.6324, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 54\n",
            "54 tensor([[ 821, 3501,  683,  ...,  494, 1036, 1040],\n",
            "        [ 220,  220,  220,  ..., 2200,  198,  220],\n",
            "        [ 220,  220,  220,  ...,  286, 3996,   11],\n",
            "        [ 220,  220,  220,  ...,  287,   13,  679]]) torch.Size([512])\n",
            "Sum loss tensor(121.6816, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 55\n",
            "55 tensor([[  220,   220,   220,  ...,   198,   220,   220],\n",
            "        [  198,   220,   220,  ...,   220, 27489,    13],\n",
            "        [  257, 15175,  6129,  ...,   220,   220,   220],\n",
            "        [  517,  4325,    13,  ...,   198,    39, 14057]]) torch.Size([512])\n",
            "Sum loss tensor(123.9931, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 56\n",
            "56 tensor([[ 198,  198, 1544,  ...,  319,  340,   13],\n",
            "        [6565, 1097,   13,  ...,  198,  197, 9099],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220]]) torch.Size([512])\n",
            "Sum loss tensor(127.9050, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 57\n",
            "57 tensor([[  220,   220,   220,  ...,   262,  3072,    13],\n",
            "        [  198,   220,   220,  ..., 50147,     8,   198],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,  1550,   257,  1310]]) torch.Size([512])\n",
            "Sum loss tensor(130.3801, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 58\n",
            "58 tensor([[  220,   220,   220,  ..., 17254,   357,    46],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,    11,   475,   484]]) torch.Size([512])\n",
            "Sum loss tensor(132.3790, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 59\n",
            "59 tensor([[ 7875,   376, 37533,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  198,   220,   220,  ...,   220,   220,   220],\n",
            "        [ 2823,   286,   262,  ...,   367,  8267,    56]]) torch.Size([512])\n",
            "Sum loss tensor(134.7135, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 60\n",
            "60 tensor([[  628,   220,   220,  ...,   220,   220,   220],\n",
            "        [  357,    53,    13,  ..., 13918,    13,   220],\n",
            "        [   12, 42633, 15867,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   503,   290, 31738]]) torch.Size([512])\n",
            "Sum loss tensor(138.2311, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 61\n",
            "61 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [ 2937, 10008,   628,  ...,    45,  4261,  5188],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  632, 23824,   198,  ...,   287,   262,  1448]]) torch.Size([512])\n",
            "Sum loss tensor(140.2993, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 62\n",
            "62 tensor([[6619,  257, 1310,  ...,  220,  220,  220],\n",
            "        [ 284,  766,  345,  ..., 3073, 1088,   11],\n",
            "        [ 220,  220,  220,  ...,  508, 5300,  198],\n",
            "        [4836,  514,  757,  ...,  220,  220,  220]]) torch.Size([512])\n",
            "Sum loss tensor(142.6353, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 63\n",
            "63 tensor([[ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [1768,   13, 1375,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220]]) torch.Size([512])\n",
            "Sum loss tensor(144.6230, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 64\n",
            "64 tensor([[ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,   13,  628,  198],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 314, 8941,  198,  ..., 7788, 2390, 1268]]) torch.Size([512])\n",
            "Sum loss tensor(146.4025, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 65\n",
            "65 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  198,   198, 13918,  ...,    13,   198,   198],\n",
            "        [ 3069,   198,   197,  ...,  4930,  3470,  5054],\n",
            "        [  220,  1400,  7510,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(151.0202, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 66\n",
            "66 tensor([[   13,   628,   198,  ...,   220,   220, 13954],\n",
            "        [  220,   220,   220,  ...,   683,   612,   764],\n",
            "        [  220,   220,   220,  ...,  1146,   621,   314],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(152.8357, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 67\n",
            "67 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,  1310,  5089,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [45484,   198,  1639,  ...,  3073,   625,   290]]) torch.Size([512])\n",
            "Sum loss tensor(155.0236, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 68\n",
            "68 tensor([[  220,   220,   220,  ...,  1586,   656,   257],\n",
            "        [ 6006, 47269,   198,  ...,  1924,    11,   911],\n",
            "        [  220,   376, 19266,  ...,   198,   220,   220],\n",
            "        [  220,   220,   220,  ...,   628,   198,   220]]) torch.Size([512])\n",
            "Sum loss tensor(157.1764, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 69\n",
            "69 tensor([[  220,   220,   220,  ...,   262,  7013, 10503],\n",
            "        [  220,   220,   220,  ...,   460,   314,   466],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(158.8938, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 70\n",
            "70 tensor([[  220,   220,   220,  ...,   628,   198,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [   34,  5549, 14386,  ...,   679, 24234,   262],\n",
            "        [  220,   262,  9970,  ...,   314,   765,   257]]) torch.Size([512])\n",
            "Sum loss tensor(161.2660, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 71\n",
            "71 tensor([[ 8893,   290, 18791,  ...,  7616,   286,   465],\n",
            "        [  198,   220,   220,  ...,   338,   257,  6175],\n",
            "        [  220,   220,   220,  ...,   665,   328,   290],\n",
            "        [ 1326,     0,   628,  ...,   198,   197,   197]]) torch.Size([512])\n",
            "Sum loss tensor(165.6175, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 72\n",
            "72 tensor([[  370, 31429,   198,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  821,  1972, 11040,  ...,   220,   220,   220],\n",
            "        [  220,   921,   290,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(167.4876, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 73\n",
            "73 tensor([[ 1137,   198,   220,  ...,  3843,  1268,   198],\n",
            "        [  220,   220,   220,  ...,  1392,   340,    13],\n",
            "        [  307,    11,  1320,  ...,   220,   220, 22108],\n",
            "        [  198,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(169.5067, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 74\n",
            "74 tensor([[20373,   198,   220,  ...,  5594,   810,   345],\n",
            "        [  220,   220,   220,  ...,   337, 48399,   319],\n",
            "        [  220,   220,   220,  ...,   357,  4215,   306],\n",
            "        [  663,  1204,    13,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(171.6630, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 75\n",
            "75 tensor([[  220,   220,   220,  ..., 27975,    50,  3268],\n",
            "        [  220,   220,   220,  ...,   220,   402, 12532],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [   13,   628,   198,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(173.4298, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 76\n",
            "76 tensor([[ 220,  220,  220,  ...,  220, 9396,  290],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220]]) torch.Size([512])\n",
            "Sum loss tensor(175.3441, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 77\n",
            "77 tensor([[  220, 15722, 10718,  ...,   220,   220,   220],\n",
            "        [  532, 37707,   628,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(177.3246, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 78\n",
            "78 tensor([[  220,   220,   220,  ...,   198,   220,   220],\n",
            "        [  284,   465,  5408,  ...,    83,  3949,   220],\n",
            "        [11441,    13,   628,  ...,    11,  4638,  5557],\n",
            "        [  220,   220,   220,  ...,   628,   198,   220]]) torch.Size([512])\n",
            "Sum loss tensor(179.4488, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 79\n",
            "79 tensor([[ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  198,  220],\n",
            "        [  13,  261,  198,  ...,  905,   13,  628],\n",
            "        [ 220,  220,  220,  ..., 7906, 5937,  287]]) torch.Size([512])\n",
            "Sum loss tensor(181.3613, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 80\n",
            "80 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  357,    46,    13,  ...,   220, 41649, 16448],\n",
            "        [  220,   220,   314,  ...,  5584,   287,   262],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(183.5941, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 81\n",
            "81 tensor([[33503,  5741, 29820,  ...,   220,   220,   220],\n",
            "        [  389, 24285,   286,  ...,   220,   220, 19116],\n",
            "        [  220,   220,   220,  ...,   220,   220,   357],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(185.5379, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 82\n",
            "82 tensor([[  220,   220,   220,  ...,  8518,    13,   198],\n",
            "        [   12, 24903,   582,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   198,   220,   220],\n",
            "        [   13,   347, 18422,  ...,   257,  4866,   286]]) torch.Size([512])\n",
            "Sum loss tensor(187.6403, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 83\n",
            "83 tensor([[ 360, 2606,   38,  ..., 1064,  644, 4073],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  628,  198,  220],\n",
            "        [ 220,  220, 5338,  ...,  198,  220,  220]]) torch.Size([512])\n",
            "Sum loss tensor(189.4154, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 84\n",
            "84 tensor([[   11, 17280,   812,  ...,  6217,  2751,     8],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220, 26494,  7228,  ...,    13, 27993,  3563],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(191.8625, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 85\n",
            "85 tensor([[  220,   220,   220,  ...,   523,  1290,   510],\n",
            "        [  220,   220,   220,  ..., 14105,   355,   262],\n",
            "        [ 2943,  8141,   198,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(193.5141, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 86\n",
            "86 tensor([[ 220,  220,  220,  ..., 1183,  423,  345],\n",
            "        [  30,  628,  198,  ...,  220,  220, 1081],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220]]) torch.Size([512])\n",
            "Sum loss tensor(195.3424, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 87\n",
            "87 tensor([[  329, 12607,    13,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  628,   198,   220,  ...,   220,   220,   220],\n",
            "        [ 2949,   986,   921,  ...,  1016,   284,  4423]]) torch.Size([512])\n",
            "Sum loss tensor(197.2221, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 88\n",
            "88 tensor([[  220,   399, 11860,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ..., 11992,  4473,    13],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(198.8433, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 89\n",
            "89 tensor([[ 1847,     8,   198,  ...,   306, 37530,    13],\n",
            "        [ 1400,   986,   345,  ...,   198,   220,   220],\n",
            "        [  220,   220,   220,  ...,  3244,   673, 23816],\n",
            "        [  465,  9941,    13,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(200.9114, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 90\n",
            "90 tensor([[ 2399,  2951,  2121,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,    26, 24863,    13],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(202.3993, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 91\n",
            "91 tensor([[  220,   220,   220,  ...,   445,    11,   198],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   679, 38806],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(204.5735, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 92\n",
            "92 tensor([[  220,   220,   220,  ...,   220,  4526, 11190],\n",
            "        [37330,    30,   921,  ...,   284,   477,   286],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  628,   198,   220,  ...,   220,   220, 42627]]) torch.Size([512])\n",
            "Sum loss tensor(206.8158, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 93\n",
            "93 tensor([[ 220,  220,  220,  ..., 1183,  651,  642],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ..., 6565, 4675, 2174],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220]]) torch.Size([512])\n",
            "Sum loss tensor(208.6679, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 94\n",
            "94 tensor([[ 220,  220, 1400,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  198,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,   70, 8101,   72]]) torch.Size([512])\n",
            "Sum loss tensor(211.1590, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 95\n",
            "95 tensor([[ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [9448, 1016,  656,  ...,  198,  197,  921]]) torch.Size([512])\n",
            "Sum loss tensor(214.7872, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 96\n",
            "96 tensor([[ 4459,    13,   887,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,  1561,   284, 21776],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [ 5699,    11,  2111,  ...,  6215, 40565,  3150]]) torch.Size([512])\n",
            "Sum loss tensor(216.5901, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 97\n",
            "97 tensor([[  220,   220,   220,  ...,  8392, 39743,   198],\n",
            "        [  220,   220,   220,  ...,   220,   412,  3069],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  257,  4046,   379,  ...,   198,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(218.5411, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 98\n",
            "98 tensor([[  220,   220,   220,  ...,    30,   628,   198],\n",
            "        [  628,   198,   220,  ...,   198,   220,   220],\n",
            "        [  703,   881,   198,  ...,   220,   220,   628],\n",
            "        [  788,   262, 38952,  ...,   319,   262,  1657]]) torch.Size([512])\n",
            "Sum loss tensor(220.5642, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 99\n",
            "99 tensor([[  220,   220,   220,  ...,   198,   220,   220],\n",
            "        [  220,   628,   198,  ...,   220,   402,  2937],\n",
            "        [30942,    13,   628,  ...,   220,   220,   220],\n",
            "        [  220,   198,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(222.5839, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 100\n",
            "100 tensor([[  220,   220,   220,  ...,   821,   198,   220],\n",
            "        [   13,   198,   220,  ...,   220,   220,   220],\n",
            "        [  286,  1393,    13,  ..., 41796,  6006,  2394],\n",
            "        [ 3420,    13,   220,  ...,     0,   679,   348]]) torch.Size([512])\n",
            "Sum loss tensor(224.5894, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 101\n",
            "101 tensor([[  198,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  262,   198,   220,  ...,   220,   220,   220],\n",
            "        [  284,   711,   257,  ...,   220,   220, 13558]]) torch.Size([512])\n",
            "Sum loss tensor(226.5642, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 102\n",
            "102 tensor([[  220,   220,   220,  ...,   503,   257, 10089],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(228.3407, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 103\n",
            "103 tensor([[  628,   198,   220,  ...,   220, 22221, 20694],\n",
            "        [  286,   514,   284,  ...,   220,   220,   220],\n",
            "        [  220,   257,  1178,  ...,   503,   319,   262],\n",
            "        [  465,   198,  2256,  ..., 15462,    11, 33658]]) torch.Size([512])\n",
            "Sum loss tensor(231.8358, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 104\n",
            "104 tensor([[  628,   198,  2390,  ..., 12265, 31884,   198],\n",
            "        [ 1155, 35064,  2573,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  286,   262,  2166,  ...,   329,  1719,   511]]) torch.Size([512])\n",
            "Sum loss tensor(234.7123, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 105\n",
            "105 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  357,  1102,   256,  ...,   220,   220,   220],\n",
            "        [  470,   198,   220,  ..., 13558,    57, 10008]]) torch.Size([512])\n",
            "Sum loss tensor(236.7251, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 106\n",
            "106 tensor([[ 1464,   198,   197,  ..., 17250,    11, 26926],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  612,   338,   428,  ...,   220,  1398,    13],\n",
            "        [ 7533, 19186,   319,  ...,   290, 16181, 48249]]) torch.Size([512])\n",
            "Sum loss tensor(239.6605, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 107\n",
            "107 tensor([[  307, 30703,   286,  ..., 25000,  2257,  4877],\n",
            "        [  679,  7228,   257,  ...,  9911,   287,  2166],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(243.0504, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 108\n",
            "108 tensor([[  220,   220,   220,  ...,  4222,    11, 42328],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  986,   628,   220,  ...,   220,   220,   220],\n",
            "        [ 9677,  9598,  2767,  ...,   284,  3809,    12]]) torch.Size([512])\n",
            "Sum loss tensor(245.0341, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 109\n",
            "109 tensor([[  628,   198,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220, 10358,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,    13,   628,   198],\n",
            "        [ 5741,   319,   257,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(246.8661, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 110\n",
            "110 tensor([[2431,   13,  628,  ...,  220,  220,  220],\n",
            "        [5511,   11, 5395,  ..., 2312,  389, 3537],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220]]) torch.Size([512])\n",
            "Sum loss tensor(248.8086, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 111\n",
            "111 tensor([[  314,  1183,  1494,  ...,   340,    13,  1375],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [37339,   338,  4641,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(250.9354, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 112\n",
            "112 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,  1119],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  628,   198, 39888,  ...,  2753,   257,  4144]]) torch.Size([512])\n",
            "Sum loss tensor(253.0322, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 113\n",
            "113 tensor([[  220,   198,   220,  ...,    60,   628,   628],\n",
            "        [  290,  8616, 20121,  ...,  5883, 29809, 12529],\n",
            "        [  329,   465,  4506,  ...,   220,   220,   220],\n",
            "        [  220,   220,  1318,  ..., 39878,     6,    50]]) torch.Size([512])\n",
            "Sum loss tensor(255.6432, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 114\n",
            "114 tensor([[  484,   779,  5108,  ...,   220,   220,   220],\n",
            "        [25262,   262,  7309,  ...,   197,   197,  3919],\n",
            "        [  220,   220,   220,  ...,     1,   532,  8147],\n",
            "        [  468,   587,   503,  ...,   220,  8621,   283]]) torch.Size([512])\n",
            "Sum loss tensor(259.6129, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 115\n",
            "115 tensor([[  628,   198,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   327,  3620,  2767],\n",
            "        [  197,   197,   197,  ...,    13, 14769, 11722],\n",
            "        [  220,   220,  2185,  ...,    40,  2390,   198]]) torch.Size([512])\n",
            "Sum loss tensor(264.1368, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 116\n",
            "116 tensor([[ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [  11,  345, 1276,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ..., 1377,  775,  389],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220]]) torch.Size([512])\n",
            "Sum loss tensor(265.6693, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 117\n",
            "117 tensor([[ 220,  220,  220,  ...,  198,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  338, 7954,  351],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220]]) torch.Size([512])\n",
            "Sum loss tensor(267.6460, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 118\n",
            "118 tensor([[  220, 12903,  2763,  ...,   991,  1839,   470],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220, 44738, 25633,  ...,   393,   772,  4574],\n",
            "        [ 6950,  1359,   198,  ..., 46663,    36,   628]]) torch.Size([512])\n",
            "Sum loss tensor(270.8308, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 119\n",
            "119 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  197,   197,   220,  ...,   321,   415,   393],\n",
            "        [  220,   412, 12038,  ...,   220,   220,   220],\n",
            "        [  220,   257, 32439,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(274.4353, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 120\n",
            "120 tensor([[ 3011,   198,   220,  ...,   220, 19061,    13],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [10490, 23660,    11,  ...,   198,   198,  1858]]) torch.Size([512])\n",
            "Sum loss tensor(276.1035, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 121\n",
            "121 tensor([[220, 220, 220,  ..., 220, 220, 220],\n",
            "        [ 13, 198,  47,  ...,  11, 339, 338],\n",
            "        [220, 220, 220,  ..., 220, 220, 220],\n",
            "        [198, 220, 220,  ..., 220, 220, 220]]) torch.Size([512])\n",
            "Sum loss tensor(277.7504, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 122\n",
            "122 tensor([[ 220,  220,  220,  ...,  986,  628,  198],\n",
            "        [ 220,  220,  921,  ..., 6405,  783,   13],\n",
            "        [ 220,  220,  220,  ...,  220,  198,  220],\n",
            "        [ 760,  644,  534,  ...,  220,  220,  220]]) torch.Size([512])\n",
            "Sum loss tensor(279.5919, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 123\n",
            "123 tensor([[  220, 41526,   198,  ...,   220,   220,   220],\n",
            "        [ 1588,   290, 49419,  ...,   220,   220,   220],\n",
            "        [  198,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,    30,   198,   220]]) torch.Size([512])\n",
            "Sum loss tensor(281.2142, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 124\n",
            "124 tensor([[  357, 37815,     6,  ..., 10863, 11598,  1222],\n",
            "        [  804,   319,   465,  ...,   198,   220,   220],\n",
            "        [  220,   198,   220,  ...,  1278,  1666,   351],\n",
            "        [  220,   220,   220,  ...,   220,  8355, 13246]]) torch.Size([512])\n",
            "Sum loss tensor(283.3326, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 125\n",
            "125 tensor([[  220,   220, 40146,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   373,  7787,   284],\n",
            "        [31812,    11,  3154,  ...,   220,   220,   220],\n",
            "        [ 1497,     8,   198,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(285.5547, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 126\n",
            "126 tensor([[  220,   220,   220,  ...,   198,   220,   220],\n",
            "        [ 1365,   407,     0,  ...,    40,  1101,   407],\n",
            "        [ 7788,  5781, 41254,  ...,  4295,  1466,   466],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(287.5595, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 127\n",
            "127 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220, 13183, 12345,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(289.4642, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 128\n",
            "128 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ..., 32737,  6177, 49349],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(291.3056, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 129\n",
            "129 tensor([[  220,   220,   220,  ...,   327,  1101,   261],\n",
            "        [ 2292,    11, 12887,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ..., 40328,   880,   510],\n",
            "        [  220,   220,   220,  ...,   220,   220,   350]]) torch.Size([512])\n",
            "Sum loss tensor(293.3427, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 130\n",
            "130 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  383,  3644, 20067,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(295.4279, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 131\n",
            "131 tensor([[  220,   220,   220,  ...,   656,   262, 25772],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,     1,   290,   438],\n",
            "        [  220,   220,   220,  ...,   198,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(297.3785, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 132\n",
            "132 tensor([[  220,   220,   220,  ...,   220,   534,  3072],\n",
            "        [   11,   319,   262,  ...,  3096,    13,   628],\n",
            "        [   11,  7178,  3245,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ..., 13938,   286,   198]]) torch.Size([512])\n",
            "Sum loss tensor(299.2848, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 133\n",
            "133 tensor([[ 1375,  9209,   287,  ...,   220,   220,   220],\n",
            "        [11691,   257,  1664,  ...,   220,   220,   220],\n",
            "        [  220,   198,   220,  ...,   220,   220,   383],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(301.2458, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 134\n",
            "134 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  466,    30,   628,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220, 20787],\n",
            "        [  220,   220,   220,  ...,    13,   198,   220]]) torch.Size([512])\n",
            "Sum loss tensor(302.9931, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 135\n",
            "135 tensor([[  220,   220,   220,  ...,   220, 26649, 30151],\n",
            "        [  656,   852,    13,  ...,   220,   220,   220],\n",
            "        [ 9265,    13,   628,  ...,    50,   337,  9947],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(304.9163, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 136\n",
            "136 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [ 1137,   220,   198,  ...,   314, 11638,   547],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(306.5670, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 137\n",
            "137 tensor([[ 6239,    32, 19269,  ...,   220,   220,   220],\n",
            "        [ 2389, 36231,   198,  ...,   220,   220,   257],\n",
            "        [  220,   220,   314,  ...,   286,  5054,  2111],\n",
            "        [  290, 46174,    13,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(308.4892, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 138\n",
            "138 tensor([[10619,  3963, 37977,  ...,   281,  1468,  1499],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   357,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(311.5822, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 139\n",
            "139 tensor([[  854,    64,   338,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220, 44849,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,  8782, 15154]]) torch.Size([512])\n",
            "Sum loss tensor(313.4176, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 140\n",
            "140 tensor([[  220,   220,   220,  ...,   649, 23275,  2485],\n",
            "        [  220,   220,   220,  ...,   683,    11,   356],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,  3516, 11103,   510]]) torch.Size([512])\n",
            "Sum loss tensor(315.0776, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 141\n",
            "141 tensor([[220, 220, 220,  ..., 220, 220, 220],\n",
            "        [910, 339, 714,  ..., 220, 220, 220],\n",
            "        [220, 220, 220,  ..., 356, 467,   0],\n",
            "        [220, 628, 220,  ..., 220, 220, 220]]) torch.Size([512])\n",
            "Sum loss tensor(316.6762, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 142\n",
            "142 tensor([[  198,   220,   220,  ...,   220,   220,  3271],\n",
            "        [  220,   220,   318,  ...,   220, 17828,    13],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  284,   262,  3084,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(318.5548, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 143\n",
            "143 tensor([[  220,   220,   220,  ...,   440,     6, 26538],\n",
            "        [   12,   593,   428,  ...,   257,   981,  1201],\n",
            "        [  256,  6021,  8347,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(320.2554, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 144\n",
            "144 tensor([[13447,    11, 16194,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,  1268,   198,   220],\n",
            "        [  198,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(321.9835, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 145\n",
            "145 tensor([[ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ..., 1368,   13,  220]]) torch.Size([512])\n",
            "Sum loss tensor(324.0267, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 146\n",
            "146 tensor([[23683, 42839,   198,  ...,  5088,   278,  2553],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(325.7202, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 147\n",
            "147 tensor([[  220,   220,   422,  ...,  6374, 39267,   532],\n",
            "        [  220,   220,  8355,  ...,   466,   345,   466],\n",
            "        [21984, 25520, 15499,  ...,   220,   220,   220],\n",
            "        [ 1119,  1210,   284,  ...,   414,   287,   220]]) torch.Size([512])\n",
            "Sum loss tensor(327.6146, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 148\n",
            "148 tensor([[220, 220, 220,  ..., 198, 220, 220],\n",
            "        [220, 220, 220,  ..., 220, 220, 220],\n",
            "        [220, 220, 220,  ..., 220, 220, 220],\n",
            "        [220, 220, 220,  ..., 220, 220, 220]]) torch.Size([512])\n",
            "Sum loss tensor(329.1677, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 149\n",
            "149 tensor([[ 220,  628,  197,  ..., 3625,  389, 4692],\n",
            "        [ 198,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220, 4526],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220]]) torch.Size([512])\n",
            "Sum loss tensor(332.1008, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 150\n",
            "150 tensor([[  220,   220,   220,  ...,   679,  4831,   625],\n",
            "        [  262, 29260, 21080,  ...,   220,   220,   220],\n",
            "        [  220,  3923,   326,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(333.9863, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 151\n",
            "151 tensor([[  345,    30,   628,  ...,  3271,   317,  1047],\n",
            "        [  220,   220,   220,  ...,   370, 31429,   198],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(335.8694, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 152\n",
            "152 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  986,   628,   198,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,  9008,    13,   314],\n",
            "        [  220,   220,   220,  ...,   220,   220, 41722]]) torch.Size([512])\n",
            "Sum loss tensor(338.0837, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 153\n",
            "153 tensor([[  220,   220,   220,  ...,   198,   220,   220],\n",
            "        [  608,    82,   262,  ...,   220,   220,   220],\n",
            "        [ 7720,    13,   198,  ...,  1194,   460,   286],\n",
            "        [  284,   616, 37111,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(340.4110, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 154\n",
            "154 tensor([[ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [  11,  314,  750,  ...,  220,  220,  220],\n",
            "        [ 628,  198,  220,  ..., 1767, 5636, 7465]]) torch.Size([512])\n",
            "Sum loss tensor(342.3171, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 155\n",
            "155 tensor([[ 262, 1388,  636,  ..., 5882, 2823,  319],\n",
            "        [ 220,  220,  220,  ...,  510,   13,  198],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220]]) torch.Size([512])\n",
            "Sum loss tensor(344.0186, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 156\n",
            "156 tensor([[  220,   220,  1422,  ...,   220,   376, 45226],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(345.7975, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 157\n",
            "157 tensor([[   11,   994,   338,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [ 3913, 41819, 46586,  ...,   220,   220,   262]]) torch.Size([512])\n",
            "Sum loss tensor(347.9343, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 158\n",
            "158 tensor([[ 198,  220,  220,  ...,    0,  628,  198],\n",
            "        [ 314, 1422,  470,  ...,  220,  220,  220],\n",
            "        [ 198,  197,  197,  ..., 2502,   11,  308],\n",
            "        [ 628,  198,  220,  ...,  220,  220, 3966]]) torch.Size([512])\n",
            "Sum loss tensor(350.7287, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 159\n",
            "159 tensor([[  220,   220,   220,  ...,   467,   736,   329],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [ 2147,   356,   714,  ...,   582,   338, 10012],\n",
            "        [ 1546, 21664,  1268,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(352.6241, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 160\n",
            "160 tensor([[  220,   220,   220,  ...,   628,   198,   220],\n",
            "        [  220,   220,   220,  ...,    13,   628,   220],\n",
            "        [   13, 31233,   468,  ...,   220,   220,   220],\n",
            "        [ 4261,   198,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(354.7910, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 161\n",
            "161 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   198,   259,  ...,   198,   198,  3152],\n",
            "        [  284,  2666,    11,  ...,   220,   220,   220],\n",
            "        [ 5149, 10897,   546,  ...,    13,   383, 32421]]) torch.Size([512])\n",
            "Sum loss tensor(357.3713, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 162\n",
            "162 tensor([[  220, 17828,    13,  ...,   220,   220,   220],\n",
            "        [  198,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(358.9606, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 163\n",
            "163 tensor([[  198,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   628,  ...,   628,   220,   220],\n",
            "        [  198,   220,   220,  ...,    40, 20634,  1546],\n",
            "        [  220,   220,   220,  ...,   220,  5870, 10008]]) torch.Size([512])\n",
            "Sum loss tensor(361.1156, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 164\n",
            "164 tensor([[220, 220, 220,  ..., 220, 220, 220],\n",
            "        [220, 220, 220,  ..., 220, 220, 220],\n",
            "        [220, 220, 220,  ..., 220, 220, 220],\n",
            "        [220, 220, 220,  ..., 220, 220, 220]]) torch.Size([512])\n",
            "Sum loss tensor(362.8615, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 165\n",
            "165 tensor([[  11, 2130,  198,  ...,   13,  628,  198],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 340,   13,  628,  ...,  628,  198,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220]]) torch.Size([512])\n",
            "Sum loss tensor(364.7657, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 166\n",
            "166 tensor([[ 220,  220,  220,  ...,  220, 1881,  835],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220]]) torch.Size([512])\n",
            "Sum loss tensor(366.7186, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 167\n",
            "167 tensor([[6998,  449, 1677,  ...,  220,  220,  220],\n",
            "        [ 198,  220,  220,  ...,  220,  220,  220],\n",
            "        [7655, 2043, 2246,  ...,  220,  220,  220],\n",
            "        [1077, 2213,  323,  ...,  628,  198,  197]]) torch.Size([512])\n",
            "Sum loss tensor(369.7938, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 168\n",
            "168 tensor([[  220,   220,  2561,  ...,   198,   220,   220],\n",
            "        [  517,   286,   198,  ...,   198,   220,   220],\n",
            "        [  220,   220,   220,  ...,   340,   318,    30],\n",
            "        [   13, 49707,    51,  ...,    11,   314,   373]]) torch.Size([512])\n",
            "Sum loss tensor(371.3948, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 169\n",
            "169 tensor([[ 6242,  6239, 20958,  ...,   326,  7510,    13],\n",
            "        [  628,   198,   220,  ...,    34,  8924, 36230],\n",
            "        [  406,  2606,   198,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(375.0933, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 170\n",
            "170 tensor([[1057,  656,  345,  ...,  220,  220,  220],\n",
            "        [ 197,  197, 7959,  ...,  319,  526,  628],\n",
            "        [ 197,   40,  760,  ...,  530, 6100,   13],\n",
            "        [ 198,  220,  220,  ...,  220,  220,  220]]) torch.Size([512])\n",
            "Sum loss tensor(380.2217, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 171\n",
            "171 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   407,   262,  3478],\n",
            "        [  220,   220,   220,  ..., 24291,    13,   198],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(381.9780, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 172\n",
            "172 tensor([[ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 262, 2854,   13,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [1723,   13,  628,  ...,  198,  197,  197]]) torch.Size([512])\n",
            "Sum loss tensor(385.2029, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 173\n",
            "173 tensor([[  383, 16759,   389,  ...,   220,   220,   220],\n",
            "        [16415,   319,    13,  ..., 10468,    11,   465],\n",
            "        [  198,  8642,   558,  ..., 24644,   198,   198],\n",
            "        [20787,   683,   262,  ...,   220,  2138,   307]]) torch.Size([512])\n",
            "Sum loss tensor(388.6986, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 174\n",
            "174 tensor([[ 1612,   284,  3852,  ...,  9370, 11651,     8],\n",
            "        [  470,   760,   703,  ...,  1053,  1392,   340],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ..., 19644, 12532,  1961]]) torch.Size([512])\n",
            "Sum loss tensor(390.3934, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 175\n",
            "175 tensor([[  220,   220,   220,  ...,   628,   198,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  921, 29470, 14433,  ...,   220,   220,   345]]) torch.Size([512])\n",
            "Sum loss tensor(392.2047, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 176\n",
            "176 tensor([[  220,   198,   220,  ...,   220,   220,   220],\n",
            "        [  198,   220,   220,  ..., 43277,  1546,   290],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(394.0562, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 177\n",
            "177 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ..., 28778,   198,   220],\n",
            "        [  220,   220,   220,  ...,  1182, 35737,    11],\n",
            "        [10008,   198,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(395.5572, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 178\n",
            "178 tensor([[   11,  8680,   284,  ...,   220,   220,   220],\n",
            "        [ 1867,   262,  5089,  ...,   220,   220,   357],\n",
            "        [  220,   220,   220,  ...,   220,   327, 12115],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(397.2647, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 179\n",
            "179 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   357,  1462,  ...,   220,   220,   220],\n",
            "        [ 3151,  7193,  1525,  ...,   220,   220,   220],\n",
            "        [  319,   606, 18479,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(398.8721, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 180\n",
            "180 tensor([[  628,   220,   220,  ...,  6665,   284,   257],\n",
            "        [  220,  6510,    13,  ...,   402,  1921,   705],\n",
            "        [  220,   220,   220,  ...,   198,   220,   220],\n",
            "        [  287,   220,   198,  ..., 26442,     8,   628]]) torch.Size([512])\n",
            "Sum loss tensor(401.8334, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 181\n",
            "181 tensor([[ 198,  220,  220,  ...,  628,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 198,  220,  220,  ..., 1961,    8,  198],\n",
            "        [ 197,  197,  197,  ...,  628,  198,  197]]) torch.Size([512])\n",
            "Sum loss tensor(405.1754, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 182\n",
            "182 tensor([[ 1583,    13,   198,  ...,  3195,    13,   628],\n",
            "        [  220,   220,   220,  ...,  2394,   357, 46437],\n",
            "        [16805,    11,  2834,  ...,  1438,   318, 10443],\n",
            "        [  338,   262,  4506,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(406.8693, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 183\n",
            "183 tensor([[  220,   220,   220,  ..., 50072,  3848,   460],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [ 3492,   287,  1315,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(408.6985, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 184\n",
            "184 tensor([[  714,   345,   307,  ...,   220,   220,   220],\n",
            "        [  220, 17486,   345,  ...,   220,   220,   220],\n",
            "        [  628,   198,   220,  ...,   555,  5162, 10676],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(410.7364, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 185\n",
            "185 tensor([[ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,   82, 6304,  470],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220]]) torch.Size([512])\n",
            "Sum loss tensor(412.4900, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 186\n",
            "186 tensor([[220, 220, 220,  ..., 220, 220, 220],\n",
            "        [220, 220, 220,  ..., 220, 220, 220],\n",
            "        [198, 197, 197,  ..., 197, 197, 197],\n",
            "        [220, 220, 220,  ..., 617, 286, 262]]) torch.Size([512])\n",
            "Sum loss tensor(415.4355, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 187\n",
            "187 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,  8740,  ...,   220,   220,   220],\n",
            "        [ 3987,  7228,  1194,  ...,   198,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220, 39319]]) torch.Size([512])\n",
            "Sum loss tensor(417.6416, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 188\n",
            "188 tensor([[  11,  644,  389,  ...,  220,  220,  220],\n",
            "        [ 198,  220,  220,  ..., 4720,  198,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  351,  257, 7014]]) torch.Size([512])\n",
            "Sum loss tensor(419.1828, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 189\n",
            "189 tensor([[  220,   628,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ..., 45164,    13,   317],\n",
            "        [  220,   220,   220,  ...,   220,   220,  3336],\n",
            "        [19363, 17369,    13,  ...,   220,   198,   220]]) torch.Size([512])\n",
            "Sum loss tensor(421.0789, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 190\n",
            "190 tensor([[  220,   220,   314,  ...,   220,   220,   220],\n",
            "        [ 2840, 36755,   284,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ..., 25860, 23017,  3671],\n",
            "        [14181,  2538,   357,  ...,    11,   345,  1839]]) torch.Size([512])\n",
            "Sum loss tensor(422.7415, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 191\n",
            "191 tensor([[26465,  3528,  1565,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,  3887,  ...,   220, 37292,  1677]]) torch.Size([512])\n",
            "Sum loss tensor(424.7462, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 192\n",
            "192 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220, 13793,  2149,  ...,   494,    11,   804],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  284,   766,    13,  ...,   220,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(426.2304, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 193\n",
            "193 tensor([[ 632,  338,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  220,  220,  ...,  220,  220,  220],\n",
            "        [ 220,  317, 9575,  ...,  220,  220,  220],\n",
            "        [ 736,   11,  345,  ...,  607, 2933,   13]]) torch.Size([512])\n",
            "Sum loss tensor(427.8886, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 194\n",
            "194 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220, 19525],\n",
            "        [11088,    13,   628,  ...,  2925,   416,    13]]) torch.Size([512])\n",
            "Sum loss tensor(429.2925, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 195\n",
            "195 tensor([[  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  371, 27143,  1546,  ..., 40438, 10206,  1377],\n",
            "        [  262, 13990,    13,  ...,   220,   220,   220],\n",
            "        [  198,   220,   220,  ...,   198,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(431.1145, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 196\n",
            "196 tensor([[  220,   220,   220,  ...,    11,  5527,    11],\n",
            "        [   11,   257, 20820,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   307,  1760,    13],\n",
            "        [  220,  4950, 47819,  ...,   198,   220,   220]]) torch.Size([512])\n",
            "Sum loss tensor(432.7563, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 197\n",
            "197 tensor([[ 2937,  1565,   198,  ...,   197, 24089,  3283],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  262, 16479,   198,  ...,   220,   220,   220],\n",
            "        [45084,   470,   588,  ...,    13,   314,  6939]]) torch.Size([512])\n",
            "Sum loss tensor(436.9023, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 198\n",
            "198 tensor([[  220,   220,   220,  ...,  1793,   314,  1043],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  220,   220,   220,  ...,   220,   220,   220],\n",
            "        [  198,   220,   220,  ..., 24742,    12,   505]]) torch.Size([512])\n",
            "Sum loss tensor(438.3425, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 199\n",
            "199 tensor([[   30,   628,   220,  ...,   220,   220,   220],\n",
            "        [ 3505,  3446,   703,  ...,   220,   220,   220],\n",
            "        [   36,    11, 24644,  ...,   220,   220,   220],\n",
            "        [  197,   197,   197,  ...,  3501,   257,  4506]]) torch.Size([512])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Sum loss tensor(441.8589, device='cuda:0') script_count 1\n",
            "script_count equal to batch_size\n",
            "batch_count 200\n",
            "sum loss 441.85888671875\n",
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "0:  plane on its way back from the Antarctic expedition with its commander, a man named Robert C. Hockney.\n",
            "\n",
            "After he was arrested on Jan. 7 at the New York Federal Prison, he was transferred to a secure part of the facility at Camp Lejeune. Hockney refused a security check and called on a group of crew that consisted of a handful of members of his crew. Hockney was an Australian citizen who came from a family of Italian and French immigrants known locally as the 'Ossans.' He had just left his home and spent the night watching TV in an asylum-seeker camp. It appears that he didn't see the people of the area but rather those who had been stranded at the other camp, a place where they were supposed to live. This is apparently what happened.\n",
            "\n",
            "A few days later, Hockney again tried to get an interview by telephone from an interpreter who offered him an opportunity to meet with his group, this time with his interpreter, Robert W. Hall. Hall had given Hockney a short statement, to which Hockney, when told of his request, gave the following answer: 'I am glad that you understand what you're going through and I appreciate the opportunity that you are having. I am a prisoner and the only thing I want for your welfare is a chance to get a look at some of the problems you are dealing with. I don't know if there will be one, but the way you've been treated is just too cruel. I understand that there is the risk you have to return. But I really believe that you are in a very bad place. You should stay, you know. You should think about why your situation isn't right. And remember that every human being has to have a human person in their lives, and I know you can't afford to let any of these people go through things like that.\"\n",
            "\n",
            "After the interpreter was finally able to get Hall to speak, Hockney left, only to be detained again by the American embassy as he left his home in Italy on Friday night, July 18. He was flown back to Europe a short time later, but was held until next week, when he was taken by a U.S. marshal to a U.S. Air Force base in Washington, where he was taken to Camp Lemonnier, another United States installation, where he was interrogated for seven hours and was asked to present the following transcript of his interview on Jan. 7:\n",
            "\n",
            "SCALIFFS: Hi, Colonel.\n",
            "\n",
            "HARTY: Thanks.\n",
            "\n",
            "(The interviewer opens)\n",
            "\n",
            "SCALIFFS: Okay.\n",
            "\n",
            "HARTY: I got back from a tour with the Americans last week when they were here about 20 minutes and I said to my first friend, I know you'll just have to give me that.\n",
            "\n",
            "(The interviewer smiles as he answers)\n",
            "\n",
            "SCALIFFS: You will be taken to Camp Lemonnier the next week. You'll go there to have a conversation about some of this other stuff.\n",
            "\n",
            "HARTY: Yes.\n",
            "\n",
            "SCALIFFS: We've got a number of issues going on here.\n",
            "\n",
            "HARTY: You will have two meetings tomorrow with our other team here and two of your family members. One of those will be here and you're allowed to sit and talk to the American agents.\n",
            "\n",
            "(The interviewer starts to describe a number of aspects of the interrogation)\n",
            "\n",
            "(The interpreter asks HARTY which of the three groups he has identified as agents or informants.)\n",
            "\n",
            "HARTY: One of them is going to the American embassy, which is a prison, as we have to go through a lot of these types of issues with each other. We will come here and sit down and talk about the issues. That's what we want to do because we really hope that you're taking the time to do that.\n",
            "\n",
            "(A group of four or five agents walks over to HARTY, and the interpreter asks him if he is allowed to sit down again.)\n",
            "\n",
            "HARTY: Sure.\n",
            "\n",
            "(The interpreter gives HARTY a small, round, unemotional hug).\n",
            "\n",
            "HARTY: But you'll be allowed to talk to the American agents or to any of the other crew members that will come down there to sit with you.\n",
            "\n",
            "HARTY: Not the American people.\n",
            "\n",
            "(HARTY stares down into the hand of the interpreter's translator, and the interpreter answers)\n",
            "\n",
            "SCALIFFS: Okay.\n",
            "\n",
            "HARTY: I have a feeling there aren't any American folks out there that could hold your hands. I'll be okay with that.\n",
            "\n",
            "(The interpreter smiles slightly)\n",
            "\n",
            "SCALIFFS: Okay.\n",
            "\n",
            "HARTY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fi-GRHFYUnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmIKpOCOYUqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEBr8YdBYUtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJkUeDbYYUwG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eedk2u18bFxq",
        "colab_type": "text"
      },
      "source": [
        "# Breaking down preparing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pui05vrJa0Tn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FILE_PATH = \"/content/drive/My Drive/WJ/film_text.txt\" # ~ 60 MB\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2-medium\")\n",
        "\n",
        "model.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qEsd7OnaxhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert os.path.isfile(FILE_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55UX9iYRYOfB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3b61922a-463c-48a3-de45-0d0ea34f921d"
      },
      "source": [
        "tokenizer.max_len, tokenizer.max_len_single_sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1024, 1024)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFZOxrpQdBag",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3d10c416-b11a-42bc-8041-a250da8f924d"
      },
      "source": [
        "block_size = 512 # I am assuming this is the size of the block that will be loaded into the training loop\n",
        "\n",
        "print('tokenizer max len', tokenizer.max_len, 'tokenizer max len single sentence')\n",
        "\n",
        "block_size = block_size - (tokenizer.max_len - tokenizer.max_len_single_sentence)\n",
        "\n",
        "directory = \"/content/drive/My Drive/WJ/\"\n",
        "filename ='film_text.txt'\n",
        "\n",
        "block_size, directory, filename"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tokenizer max len 1024 tokenizer max len single sentence\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(512, '/content/drive/My Drive/WJ/', 'film_text.txt')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngLHa70LdBdK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c509af4f-7e1c-40e8-c256-5bf892ed4a90"
      },
      "source": [
        "cached_features_file = os.path.join(directory, \"gpt2\" + \"_\" + str(block_size) + \"_\" + filename)\n",
        "cached_features_file"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/WJ/gpt2_512_film_text.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrsbDi53dBf9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a43c3fc9-b958-4f91-b11f-d118516f6e28"
      },
      "source": [
        "overwrite_cache = False\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "if os.path.exists(cached_features_file) and not overwrite_cache: #if it already exists, don't overwrite if overwite_cache set to False\n",
        "      print('Loading featues from cached file')\n",
        "      logger.info(f\"Loading features from your cached file {cached_features_file}\") # report event\n",
        "\n",
        "      with open(cached_features_file, \"rb\") as cache:\n",
        "                self.examples = pickle.load(cache) #take binary data and deserialize to use \n",
        "                logger.debug(\"Loaded examples from cache\")\n",
        "\n",
        "else:\n",
        "      logger.info(f\"Creating features from file {filename} at {directory}\") #report event\n",
        "      print('Creating features from file')\n",
        "\n",
        "     "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating features from file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4_kzpNdNDM8",
        "colab_type": "text"
      },
      "source": [
        "Let's  breakdown what is happening inside the second else:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pe-Oco3dBiW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f64ca473-b8fb-4264-d3ba-b2ebabb4a282"
      },
      "source": [
        "self.examples = []\n",
        "\n",
        "with open(FILE_PATH, encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "    print('read_file')\n",
        "    logger.debug(\"Succesfully read text from file\")\n",
        "\n",
        "#tokenize the text\n",
        "# convert_tokens_to_ids = Converts a token string (or a sequence of tokens) in a single integer id (or sequence of ids), using the vocabulary\n",
        "tokenized_text = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "read_file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTcZaAHoRD3-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c8b3b1bf-7d22-4da2-b188-f98806c0f079"
      },
      "source": [
        "len(tokenized_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28066436"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX9yU-N3dBk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "examples = []\n",
        "\n",
        "for i in range(0, len(tokenized_text)-block_size +1, block_size):\n",
        "      examples.append(\n",
        "      tokenizer.build_inputs_with_special_tokens(\n",
        "          tokenized_text[i:i+block_size]\n",
        "      )\n",
        "  )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwdFFyY0dBnd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c7d24339-f3de-45c0-f4bc-1bce7f57b1de"
      },
      "source": [
        "len(examples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "54817"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUns7DHwWC4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "examples[9]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0wfHzLeFafS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b330dcdd-503f-4235-ba4e-7c38447b2434"
      },
      "source": [
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htuU1u880Sjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}